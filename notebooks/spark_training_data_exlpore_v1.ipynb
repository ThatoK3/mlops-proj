{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc191bdf-38ce-4485-9aeb-fc724e253fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"S3AvroAnalytics\")\n",
    "    .config(\"spark.jars\", \"/drivers/postgresql-42.5.0.jar\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "524418d7-a9ab-42c1-9669-9dfc1dd6d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a8af24c-4508-4b2e-9b58-3af9d27d1b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read json files from S3\n",
    "input_path = \"s3a://mlops-proj-bucket/topics/csv-data-topic/\"\n",
    "df = spark.read.format(\"json\").load(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b66f6b71-1ebb-4d08-89c3-f1bbafa8bec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- avg_glucose_level: string (nullable = true)\n",
      " |-- bmi: string (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- heart_disease: string (nullable = true)\n",
      " |-- hypertension: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- smoking_status: string (nullable = true)\n",
      " |-- stroke: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      "\n",
      "+--------------+---+-----------------+----+------------+------+-------------+------------+-----+---------------+------+-------------+---------+\n",
      "|Residence_type|age|avg_glucose_level|bmi |ever_married|gender|heart_disease|hypertension|id   |smoking_status |stroke|work_type    |partition|\n",
      "+--------------+---+-----------------+----+------------+------+-------------+------------+-----+---------------+------+-------------+---------+\n",
      "|Urban         |64 |74.1             |28.8|Yes         |Male  |1            |0           |12363|Unknown        |1     |Govt_job     |0        |\n",
      "|Rural         |77 |190.32           |31.4|Yes         |Female|0            |0           |63973|never smoked   |1     |Govt_job     |0        |\n",
      "|Rural         |74 |231.61           |34.6|Yes         |Female|0            |0           |45277|formerly smoked|1     |Private      |0        |\n",
      "|Rural         |81 |78.7             |19.4|Yes         |Female|1            |0           |4712 |Unknown        |1     |Self-employed|0        |\n",
      "|Urban         |57 |110.52           |28.5|Yes         |Female|0            |0           |33175|Unknown        |1     |Govt_job     |0        |\n",
      "+--------------+---+-----------------+----+------------+------+-------------+------------+-----+---------------+------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1470ad00-e72c-4284-806b-0e53d8d03351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Residence_type',\n",
       " 'age',\n",
       " 'avg_glucose_level',\n",
       " 'bmi',\n",
       " 'ever_married',\n",
       " 'gender',\n",
       " 'heart_disease',\n",
       " 'hypertension',\n",
       " 'id',\n",
       " 'smoking_status',\n",
       " 'stroke',\n",
       " 'work_type',\n",
       " 'partition']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a42b6b99-c754-4c02-8e16-4aa1ee99d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary view for SQL queries\n",
    "df.createOrReplaceTempView(\"stroke_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c30ef96a-e76e-4860-bd4b-51c962b3f1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET OVERVIEW ===\n",
      "+-------------+---------------+-----------------+------------------+-----------------+\n",
      "|total_records|unique_patients|          avg_age|       avg_glucose|          avg_bmi|\n",
      "+-------------+---------------+-----------------+------------------+-----------------+\n",
      "|         5100|           5100|43.21215686274512|106.16418431372549|28.89275510204084|\n",
      "+-------------+---------------+-----------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic dataset overview\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) as total_records,\n",
    "    COUNT(DISTINCT id) as unique_patients,\n",
    "    AVG(CAST(age AS DOUBLE)) as avg_age,\n",
    "    AVG(CAST(avg_glucose_level AS DOUBLE)) as avg_glucose,\n",
    "    AVG(CAST(bmi AS DOUBLE)) as avg_bmi\n",
    "FROM stroke_data\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f726a095-5518-4587-a1eb-312d3475917c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STROKE DISTRIBUTION ===\n",
      "+------+-----+----------+\n",
      "|stroke|count|percentage|\n",
      "+------+-----+----------+\n",
      "|     0| 4852|     95.14|\n",
      "|     1|  248|      4.86|\n",
      "+------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stroke distribution\n",
    "print(\"=== STROKE DISTRIBUTION ===\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    stroke,\n",
    "    COUNT(*) as count,\n",
    "    ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM stroke_data), 2) as percentage\n",
    "FROM stroke_data\n",
    "GROUP BY stroke\n",
    "ORDER BY stroke\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65516205-faf5-4953-968e-c5aa509a5a5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STROKE RATE BY GENDER ===\n",
      "+------+-----+------------+-------------------+\n",
      "|gender|total|stroke_cases|stroke_rate_percent|\n",
      "+------+-----+------------+-------------------+\n",
      "|  Male| 2113|         107|               5.06|\n",
      "|Female| 2986|         141|               4.72|\n",
      "| Other|    1|           0|               0.00|\n",
      "+------+-----+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stroke rate by gender\n",
    "print(\"=== STROKE RATE BY GENDER ===\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    gender,\n",
    "    COUNT(*) as total,\n",
    "    SUM(CAST(stroke AS INT)) as stroke_cases,\n",
    "    ROUND(SUM(CAST(stroke AS INT)) * 100.0 / COUNT(*), 2) as stroke_rate_percent\n",
    "FROM stroke_data\n",
    "GROUP BY gender\n",
    "ORDER BY stroke_rate_percent DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "628191e4-df86-47c6-81be-01ddcb56403c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AGE DISTRIBUTION AND STROKE RISK ===\n",
      "+---------+-----+------------+-------------------+\n",
      "|age_group|total|stroke_cases|stroke_rate_percent|\n",
      "+---------+-----+------------+-------------------+\n",
      "|  Over 60| 1301|         176|              13.53|\n",
      "|    46-60| 1186|          59|               4.97|\n",
      "|    30-45| 1100|          11|               1.00|\n",
      "| Under 30| 1513|           2|               0.13|\n",
      "+---------+-----+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Age distribution and stroke risk\n",
    "print(\"=== AGE DISTRIBUTION AND STROKE RISK ===\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    CASE \n",
    "        WHEN CAST(age AS INT) < 30 THEN 'Under 30'\n",
    "        WHEN CAST(age AS INT) BETWEEN 30 AND 45 THEN '30-45'\n",
    "        WHEN CAST(age AS INT) BETWEEN 46 AND 60 THEN '46-60'\n",
    "        WHEN CAST(age AS INT) > 60 THEN 'Over 60'\n",
    "    END as age_group,\n",
    "    COUNT(*) as total,\n",
    "    SUM(CAST(stroke AS INT)) as stroke_cases,\n",
    "    ROUND(SUM(CAST(stroke AS INT)) * 100.0 / COUNT(*), 2) as stroke_rate_percent\n",
    "FROM stroke_data\n",
    "GROUP BY age_group\n",
    "ORDER BY stroke_rate_percent DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb0dfb25-4b1c-4e9f-99bc-3d4deb11f63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HYPERTENSION & HEART DISEASE IMPACT ===\n",
      "+------------+-------------+-----+------------+-------------------+\n",
      "|hypertension|heart_disease|total|stroke_cases|stroke_rate_percent|\n",
      "+------------+-------------+-----+------------+-------------------+\n",
      "|           1|            1|   64|          13|              20.31|\n",
      "|           0|            1|  212|          33|              15.57|\n",
      "|           1|            0|  432|          53|              12.27|\n",
      "|           0|            0| 4392|         149|               3.39|\n",
      "+------------+-------------+-----+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hypertension and heart disease impact\n",
    "print(\"=== HYPERTENSION & HEART DISEASE IMPACT ===\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    hypertension,\n",
    "    heart_disease,\n",
    "    COUNT(*) as total,\n",
    "    SUM(CAST(stroke AS INT)) as stroke_cases,\n",
    "    ROUND(SUM(CAST(stroke AS INT)) * 100.0 / COUNT(*), 2) as stroke_rate_percent\n",
    "FROM stroke_data\n",
    "GROUP BY hypertension, heart_disease\n",
    "ORDER BY stroke_rate_percent DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59aa698b-a158-4b8f-a9d5-9e99fd50ecb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SMOKING STATUS ANALYSIS ===\n",
      "+---------------+-----+------------+-------------------+\n",
      "| smoking_status|total|stroke_cases|stroke_rate_percent|\n",
      "+---------------+-----+------------+-------------------+\n",
      "|formerly smoked|  884|          69|               7.81|\n",
      "|         smokes|  789|          42|               5.32|\n",
      "|   never smoked| 1887|          90|               4.77|\n",
      "|        Unknown| 1540|          47|               3.05|\n",
      "+---------------+-----+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Smoking status analysis\n",
    "print(\"=== SMOKING STATUS ANALYSIS ===\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    smoking_status,\n",
    "    COUNT(*) as total,\n",
    "    SUM(CAST(stroke AS INT)) as stroke_cases,\n",
    "    ROUND(SUM(CAST(stroke AS INT)) * 100.0 / COUNT(*), 2) as stroke_rate_percent\n",
    "FROM stroke_data\n",
    "GROUP BY smoking_status\n",
    "ORDER BY stroke_rate_percent DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abc1885a-1d09-4668-b1ef-fa0b8c0a7f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== WORK TYPE AND STROKE RISK ===\n",
      "+-------------+-----+------------+-------------------+\n",
      "|    work_type|total|stroke_cases|stroke_rate_percent|\n",
      "+-------------+-----+------------+-------------------+\n",
      "|Self-employed|  816|          65|               7.97|\n",
      "|      Private| 2920|         148|               5.07|\n",
      "|     Govt_job|  656|          33|               5.03|\n",
      "|     children|  686|           2|               0.29|\n",
      "| Never_worked|   22|           0|               0.00|\n",
      "+-------------+-----+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Work type and stroke risk\n",
    "print(\"=== WORK TYPE AND STROKE RISK ===\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    work_type,\n",
    "    COUNT(*) as total,\n",
    "    SUM(CAST(stroke AS INT)) as stroke_cases,\n",
    "    ROUND(SUM(CAST(stroke AS INT)) * 100.0 / COUNT(*), 2) as stroke_rate_percent\n",
    "FROM stroke_data\n",
    "GROUP BY work_type\n",
    "ORDER BY stroke_rate_percent DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddb461be-17c2-448c-9c88-fc73dc3c44a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GLUCOSE LEVEL ANALYSIS ===\n",
      "+------+-----------+-----------+-----------+-----------+\n",
      "|stroke|avg_glucose|min_glucose|max_glucose|std_glucose|\n",
      "+------+-----------+-----------+-----------+-----------+\n",
      "|     0|     104.84|      55.12|     267.76|       43.9|\n",
      "|     1|     132.16|      56.11|     271.74|      61.74|\n",
      "+------+-----------+-----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Glucose level analysis by stroke status\n",
    "print(\"=== GLUCOSE LEVEL ANALYSIS ===\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    stroke,\n",
    "    ROUND(AVG(CAST(avg_glucose_level AS DOUBLE)), 2) as avg_glucose,\n",
    "    ROUND(MIN(CAST(avg_glucose_level AS DOUBLE)), 2) as min_glucose,\n",
    "    ROUND(MAX(CAST(avg_glucose_level AS DOUBLE)), 2) as max_glucose,\n",
    "    ROUND(STDDEV(CAST(avg_glucose_level AS DOUBLE)), 2) as std_glucose\n",
    "FROM stroke_data\n",
    "GROUP BY stroke\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5344a424-dd75-4f37-88b7-748db79c1d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BMI ANALYSIS ===\n",
      "+------+-------+-------+-------+\n",
      "|stroke|avg_bmi|min_bmi|max_bmi|\n",
      "+------+-------+-------+-------+\n",
      "|     0|  28.82|   10.3|   97.6|\n",
      "|     1|  30.44|   16.9|   56.6|\n",
      "+------+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BMI analysis by stroke status\n",
    "print(\"=== BMI ANALYSIS ===\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    stroke,\n",
    "    ROUND(AVG(CASE WHEN bmi != 'N/A' THEN CAST(bmi AS DOUBLE) ELSE NULL END), 2) as avg_bmi,\n",
    "    ROUND(MIN(CASE WHEN bmi != 'N/A' THEN CAST(bmi AS DOUBLE) ELSE NULL END), 2) as min_bmi,\n",
    "    ROUND(MAX(CASE WHEN bmi != 'N/A' THEN CAST(bmi AS DOUBLE) ELSE NULL END), 2) as max_bmi\n",
    "FROM stroke_data\n",
    "GROUP BY stroke\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93df4198-cacd-4d99-bd69-41a46aa42f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESIDENCE TYPE COMPARISON ===\n",
      "+--------------+-----+------------+-------------------+-------+\n",
      "|Residence_type|total|stroke_cases|stroke_rate_percent|avg_age|\n",
      "+--------------+-----+------------+-------------------+-------+\n",
      "|         Urban| 2591|         134|               5.17|  43.52|\n",
      "|         Rural| 2509|         114|               4.54|  42.89|\n",
      "+--------------+-----+------------+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Residence type comparison\n",
    "print(\"=== RESIDENCE TYPE COMPARISON ===\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    Residence_type,\n",
    "    COUNT(*) as total,\n",
    "    SUM(CAST(stroke AS INT)) as stroke_cases,\n",
    "    ROUND(SUM(CAST(stroke AS INT)) * 100.0 / COUNT(*), 2) as stroke_rate_percent,\n",
    "    ROUND(AVG(CAST(age AS DOUBLE)), 2) as avg_age\n",
    "FROM stroke_data\n",
    "GROUP BY Residence_type\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "396ea84d-cf16-486d-9216-0ca359dc79f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MULTI-FACTOR RISK ANALYSIS ===\n",
      "+------------+-------------+---------------+-----+------------+-------------------+\n",
      "|hypertension|heart_disease| smoking_status|total|stroke_cases|stroke_rate_percent|\n",
      "+------------+-------------+---------------+-----+------------+-------------------+\n",
      "|           1|            1|         smokes|   15|           5|              33.33|\n",
      "|           0|            1|         smokes|   46|          10|              21.74|\n",
      "|           1|            1|formerly smoked|   21|           4|              19.05|\n",
      "|           0|            1|        Unknown|   43|           8|              18.60|\n",
      "|           1|            1|   never smoked|   23|           4|              17.39|\n",
      "|           1|            0|formerly smoked|   99|          15|              15.15|\n",
      "|           1|            0|   never smoked|  207|          28|              13.53|\n",
      "|           0|            1|formerly smoked|   56|           7|              12.50|\n",
      "|           0|            1|   never smoked|   67|           8|              11.94|\n",
      "|           1|            0|        Unknown|   47|           4|               8.51|\n",
      "+------------+-------------+---------------+-----+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multi-factor risk analysis\n",
    "print(\"=== MULTI-FACTOR RISK ANALYSIS ===\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    hypertension,\n",
    "    heart_disease,\n",
    "    smoking_status,\n",
    "    COUNT(*) as total,\n",
    "    SUM(CAST(stroke AS INT)) as stroke_cases,\n",
    "    ROUND(SUM(CAST(stroke AS INT)) * 100.0 / COUNT(*), 2) as stroke_rate_percent\n",
    "FROM stroke_data\n",
    "GROUP BY hypertension, heart_disease, smoking_status\n",
    "HAVING COUNT(*) > 10  -- Only show groups with sufficient data\n",
    "ORDER BY stroke_rate_percent DESC\n",
    "LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c0055cc-b2c6-4a3b-bd0b-6652a91e5a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BMI DATA QUALITY ===\n",
      "+-------------+-----------+-------------------+\n",
      "|total_records|missing_bmi|missing_bmi_percent|\n",
      "+-------------+-----------+-------------------+\n",
      "|         5100|        200|               3.92|\n",
      "+-------------+-----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data quality check for BMI\n",
    "print(\"=== BMI DATA QUALITY ===\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) as total_records,\n",
    "    SUM(CASE WHEN bmi = 'N/A' THEN 1 ELSE 0 END) as missing_bmi,\n",
    "    ROUND(SUM(CASE WHEN bmi = 'N/A' THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) as missing_bmi_percent\n",
    "FROM stroke_data\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60ed89c1-ee17-4d73-9038-642cf5bf40bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AGE vs GLUCOSE LEVEL ===\n",
      "+------+-----------------------+\n",
      "|stroke|age_glucose_correlation|\n",
      "+------+-----------------------+\n",
      "|     0|                  0.223|\n",
      "|     1|                   0.11|\n",
      "+------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Age vs Glucose level correlation by stroke\n",
    "print(\"=== AGE vs GLUCOSE LEVEL ===\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    stroke,\n",
    "    ROUND(CORR(CAST(age AS DOUBLE), CAST(avg_glucose_level AS DOUBLE)), 3) as age_glucose_correlation\n",
    "FROM stroke_data\n",
    "GROUP BY stroke\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5b6a02c-4675-48e0-8dca-f2b16db69f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HIGH-RISK PROFILES ===\n",
      "+---------------+----------+\n",
      "|high_risk_count|percentage|\n",
      "+---------------+----------+\n",
      "|             66|      1.29|\n",
      "+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# High-risk profile identification\n",
    "print(\"=== HIGH-RISK PROFILES ===\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) as high_risk_count,\n",
    "    ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM stroke_data), 2) as percentage\n",
    "FROM stroke_data\n",
    "WHERE \n",
    "    CAST(age AS INT) > 60 \n",
    "    AND CAST(hypertension AS INT) = 1 \n",
    "    AND CAST(avg_glucose_level AS DOUBLE) > 200\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25e02e9a-0953-4d15-83e6-4221b142124b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NUMERICAL COLUMNS SUMMARY ===\n",
      "+-----------------+---------+---------+---------+---------+\n",
      "|      column_name|min_value|max_value|avg_value|std_value|\n",
      "+-----------------+---------+---------+---------+---------+\n",
      "|              age|     0.08|     82.0|    43.21|    22.61|\n",
      "|avg_glucose_level|    55.12|   271.74|   106.16|    45.31|\n",
      "|              bmi|     10.3|     97.6|    28.89|     7.85|\n",
      "+-----------------+---------+---------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics for numerical columns\n",
    "print(\"=== NUMERICAL COLUMNS SUMMARY ===\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    'age' as column_name,\n",
    "    ROUND(MIN(CAST(age AS DOUBLE)), 2) as min_value,\n",
    "    ROUND(MAX(CAST(age AS DOUBLE)), 2) as max_value,\n",
    "    ROUND(AVG(CAST(age AS DOUBLE)), 2) as avg_value,\n",
    "    ROUND(STDDEV(CAST(age AS DOUBLE)), 2) as std_value\n",
    "FROM stroke_data\n",
    "UNION ALL\n",
    "SELECT \n",
    "    'avg_glucose_level' as column_name,\n",
    "    ROUND(MIN(CAST(avg_glucose_level AS DOUBLE)), 2) as min_value,\n",
    "    ROUND(MAX(CAST(avg_glucose_level AS DOUBLE)), 2) as max_value,\n",
    "    ROUND(AVG(CAST(avg_glucose_level AS DOUBLE)), 2) as avg_value,\n",
    "    ROUND(STDDEV(CAST(avg_glucose_level AS DOUBLE)), 2) as std_value\n",
    "FROM stroke_data\n",
    "UNION ALL\n",
    "SELECT \n",
    "    'bmi' as column_name,\n",
    "    ROUND(MIN(CASE WHEN bmi != 'N/A' THEN CAST(bmi AS DOUBLE) ELSE NULL END), 2) as min_value,\n",
    "    ROUND(MAX(CASE WHEN bmi != 'N/A' THEN CAST(bmi AS DOUBLE) ELSE NULL END), 2) as max_value,\n",
    "    ROUND(AVG(CASE WHEN bmi != 'N/A' THEN CAST(bmi AS DOUBLE) ELSE NULL END), 2) as avg_value,\n",
    "    ROUND(STDDEV(CASE WHEN bmi != 'N/A' THEN CAST(bmi AS DOUBLE) ELSE NULL END), 2) as std_value\n",
    "FROM stroke_data\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64a49779-8bdd-4972-8d85-6e3b7d0120e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PATIENT RISK RANKING ===\n",
      "+-----+---+-----------------+----+------------+-------------+------+----------+---------+\n",
      "|   id|age|avg_glucose_level| bmi|hypertension|heart_disease|stroke|risk_score|risk_rank|\n",
      "+-----+---+-----------------+----+------------+-------------+------+----------+---------+\n",
      "|20463| 81|           250.89|28.1|           1|            1|     1|     71.81|        1|\n",
      "|67895| 82|           215.94|27.9|           1|            1|     1|     71.76|        2|\n",
      "|65955| 81|           220.64|  30|           1|            1|     0|     71.51|        3|\n",
      "|63836| 81|           217.94|24.1|           1|            1|     0|     71.48|        4|\n",
      "|68627| 80|           175.29|31.5|           1|            1|     1|     70.75|        5|\n",
      "|62791| 79|           205.23|  22|           1|            1|     0|     70.75|        6|\n",
      "|28333| 79|           200.28|  30|           1|            1|     0|      70.7|        7|\n",
      "|54353| 78|           227.16|41.7|           1|            1|     0|     70.67|        8|\n",
      "|19271| 82|           101.56|31.5|           1|            1|     0|     70.62|        9|\n",
      "|70497| 81|           126.34|27.4|           1|            1|     0|     70.56|       10|\n",
      "+-----+---+-----------------+----+------------+-------------+------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Window functions for patient ranking\n",
    "print(\"=== PATIENT RISK RANKING ===\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    id,\n",
    "    age,\n",
    "    avg_glucose_level,\n",
    "    bmi,\n",
    "    hypertension,\n",
    "    heart_disease,\n",
    "    stroke,\n",
    "    ROUND(CAST(age AS DOUBLE) * 0.3 + \n",
    "          CAST(avg_glucose_level AS DOUBLE) * 0.01 + \n",
    "          CAST(hypertension AS INT) * 20 + \n",
    "          CAST(heart_disease AS INT) * 25, 2) as risk_score,\n",
    "    RANK() OVER (ORDER BY CAST(age AS DOUBLE) * 0.3 + \n",
    "                 CAST(avg_glucose_level AS DOUBLE) * 0.01 + \n",
    "                 CAST(hypertension AS INT) * 20 + \n",
    "                 CAST(heart_disease AS INT) * 25 DESC) as risk_rank\n",
    "FROM stroke_data\n",
    "WHERE bmi != 'N/A'\n",
    "ORDER BY risk_score DESC\n",
    "LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de9faa3f-9435-4811-93e9-fb50a6d8cfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PIVOT: STROKE RATE BY AGE GROUP AND GENDER ===\n",
      "+------+--------------------+-------------------+\n",
      "|gender|under_50_stroke_rate|over_50_stroke_rate|\n",
      "+------+--------------------+-------------------+\n",
      "|Female|                0.82|              10.00|\n",
      "|  Male|                0.51|              10.80|\n",
      "| Other|                0.00|               NULL|\n",
      "+------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pivot table - Stroke rate by age group and gender\n",
    "print(\"=== PIVOT: STROKE RATE BY AGE GROUP AND GENDER ===\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    gender,\n",
    "    ROUND(\n",
    "        SUM(CASE WHEN CAST(age AS INT) < 50 AND stroke = '1' THEN 1 ELSE 0 END) * 100.0 / \n",
    "        NULLIF(SUM(CASE WHEN CAST(age AS INT) < 50 THEN 1 ELSE 0 END), 0), \n",
    "        2\n",
    "    ) as under_50_stroke_rate,\n",
    "    ROUND(\n",
    "        SUM(CASE WHEN CAST(age AS INT) >= 50 AND stroke = '1' THEN 1 ELSE 0 END) * 100.0 / \n",
    "        NULLIF(SUM(CASE WHEN CAST(age AS INT) >= 50 THEN 1 ELSE 0 END), 0), \n",
    "        2\n",
    "    ) as over_50_stroke_rate\n",
    "FROM stroke_data\n",
    "GROUP BY gender\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07148ec-a06d-4d71-8fe3-2bea9167e695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
