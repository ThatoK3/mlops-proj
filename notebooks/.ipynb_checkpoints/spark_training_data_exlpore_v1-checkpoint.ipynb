{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc191bdf-38ce-4485-9aeb-fc724e253fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"S3AvroAnalytics\")\n",
    "    .config(\"spark.jars\", \"/drivers/postgresql-42.5.0.jar\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "524418d7-a9ab-42c1-9669-9dfc1dd6d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a8af24c-4508-4b2e-9b58-3af9d27d1b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read json files from S3\n",
    "input_path = \"s3a://mlops-proj-bucket/topics/csv-data-topic/\"\n",
    "df = spark.read.format(\"json\").load(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b66f6b71-1ebb-4d08-89c3-f1bbafa8bec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Residence_type: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- avg_glucose_level: string (nullable = true)\n",
      " |-- bmi: string (nullable = true)\n",
      " |-- ever_married: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- heart_disease: string (nullable = true)\n",
      " |-- hypertension: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- smoking_status: string (nullable = true)\n",
      " |-- stroke: string (nullable = true)\n",
      " |-- work_type: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      "\n",
      "+--------------+---+-----------------+----+------------+------+-------------+------------+-----+---------------+------+-------------+---------+\n",
      "|Residence_type|age|avg_glucose_level|bmi |ever_married|gender|heart_disease|hypertension|id   |smoking_status |stroke|work_type    |partition|\n",
      "+--------------+---+-----------------+----+------------+------+-------------+------------+-----+---------------+------+-------------+---------+\n",
      "|Urban         |64 |74.1             |28.8|Yes         |Male  |1            |0           |12363|Unknown        |1     |Govt_job     |0        |\n",
      "|Rural         |77 |190.32           |31.4|Yes         |Female|0            |0           |63973|never smoked   |1     |Govt_job     |0        |\n",
      "|Rural         |74 |231.61           |34.6|Yes         |Female|0            |0           |45277|formerly smoked|1     |Private      |0        |\n",
      "|Rural         |81 |78.7             |19.4|Yes         |Female|1            |0           |4712 |Unknown        |1     |Self-employed|0        |\n",
      "|Urban         |57 |110.52           |28.5|Yes         |Female|0            |0           |33175|Unknown        |1     |Govt_job     |0        |\n",
      "+--------------+---+-----------------+----+------------+------+-------------+------------+-----+---------------+------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1470ad00-e72c-4284-806b-0e53d8d03351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Residence_type',\n",
       " 'age',\n",
       " 'avg_glucose_level',\n",
       " 'bmi',\n",
       " 'ever_married',\n",
       " 'gender',\n",
       " 'heart_disease',\n",
       " 'hypertension',\n",
       " 'id',\n",
       " 'smoking_status',\n",
       " 'stroke',\n",
       " 'work_type',\n",
       " 'partition']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a42b6b99-c754-4c02-8e16-4aa1ee99d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary view for SQL queries\n",
    "df.createOrReplaceTempView(\"stroke_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c30ef96a-e76e-4860-bd4b-51c962b3f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset overview\n",
    "dataset_overview = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) as total_records,\n",
    "    COUNT(DISTINCT id) as unique_patients,\n",
    "    AVG(CAST(age AS DOUBLE)) as avg_age,\n",
    "    AVG(CAST(avg_glucose_level AS DOUBLE)) as avg_glucose,\n",
    "    AVG(CAST(bmi AS DOUBLE)) as avg_bmi\n",
    "FROM stroke_data\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e23607f-410c-4ccb-9f3a-f5c69917defb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+-----------------+------------------+-----------------+\n",
      "|total_records|unique_patients|avg_age          |avg_glucose       |avg_bmi          |\n",
      "+-------------+---------------+-----------------+------------------+-----------------+\n",
      "|5100         |5100           |43.21215686274512|106.16418431372549|28.89275510204084|\n",
      "+-------------+---------------+-----------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_overview.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f726a095-5518-4587-a1eb-312d3475917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stroke distribution\n",
    "stroke_distribution=spark.sql(\"\"\"\n",
    "SELECT \n",
    "    stroke,\n",
    "    COUNT(*) as count,\n",
    "    ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM stroke_data), 2) as percentage\n",
    "FROM stroke_data\n",
    "GROUP BY stroke\n",
    "ORDER BY stroke\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4bae0ac8-fb6e-4c24-bdec-c628f603fa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----------+\n",
      "|stroke|count|percentage|\n",
      "+------+-----+----------+\n",
      "|     0| 4852|     95.14|\n",
      "|     1|  248|      4.86|\n",
      "+------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stroke_distribution.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65516205-faf5-4953-968e-c5aa509a5a5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stroke rate by gender\n",
    "gender_analysis = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    gender,\n",
    "    COUNT(*) as total,\n",
    "    SUM(CAST(stroke AS INT)) as stroke_cases,\n",
    "    ROUND(SUM(CAST(stroke AS INT)) * 100.0 / COUNT(*), 2) as stroke_rate_percent\n",
    "FROM stroke_data\n",
    "GROUP BY gender\n",
    "ORDER BY stroke_rate_percent DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "160e55d9-f465-4a1f-b926-9c4e974eb4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------------+-------------------+\n",
      "|gender|total|stroke_cases|stroke_rate_percent|\n",
      "+------+-----+------------+-------------------+\n",
      "|  Male| 2113|         107|               5.06|\n",
      "|Female| 2986|         141|               4.72|\n",
      "| Other|    1|           0|               0.00|\n",
      "+------+-----+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gender_analysis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "628191e4-df86-47c6-81be-01ddcb56403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distribution and stroke risk\n",
    "age_group_analysis = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    CASE \n",
    "        WHEN CAST(age AS INT) < 30 THEN 'Under 30'\n",
    "        WHEN CAST(age AS INT) BETWEEN 30 AND 45 THEN '30-45'\n",
    "        WHEN CAST(age AS INT) BETWEEN 46 AND 60 THEN '46-60'\n",
    "        WHEN CAST(age AS INT) > 60 THEN 'Over 60'\n",
    "    END as age_group,\n",
    "    COUNT(*) as total,\n",
    "    SUM(CAST(stroke AS INT)) as stroke_cases,\n",
    "    ROUND(SUM(CAST(stroke AS INT)) * 100.0 / COUNT(*), 2) as stroke_rate_percent\n",
    "FROM stroke_data\n",
    "GROUP BY age_group\n",
    "ORDER BY stroke_rate_percent DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78652bc7-ecba-4998-8606-e0fb2e58b1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------------+-------------------+\n",
      "|age_group|total|stroke_cases|stroke_rate_percent|\n",
      "+---------+-----+------------+-------------------+\n",
      "|  Over 60| 1301|         176|              13.53|\n",
      "|    46-60| 1186|          59|               4.97|\n",
      "|    30-45| 1100|          11|               1.00|\n",
      "| Under 30| 1513|           2|               0.13|\n",
      "+---------+-----+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "age_group_analysis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb0dfb25-4b1c-4e9f-99bc-3d4deb11f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypertension and heart disease impact\n",
    "hypertension_heart_disease_analysis = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    hypertension,\n",
    "    heart_disease,\n",
    "    COUNT(*) as total,\n",
    "    SUM(CAST(stroke AS INT)) as stroke_cases,\n",
    "    ROUND(SUM(CAST(stroke AS INT)) * 100.0 / COUNT(*), 2) as stroke_rate_percent\n",
    "FROM stroke_data\n",
    "GROUP BY hypertension, heart_disease\n",
    "ORDER BY stroke_rate_percent DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa7fa9d7-410e-40fa-80e8-f60fa8f6aa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-----+------------+-------------------+\n",
      "|hypertension|heart_disease|total|stroke_cases|stroke_rate_percent|\n",
      "+------------+-------------+-----+------------+-------------------+\n",
      "|           1|            1|   64|          13|              20.31|\n",
      "|           0|            1|  212|          33|              15.57|\n",
      "|           1|            0|  432|          53|              12.27|\n",
      "|           0|            0| 4392|         149|               3.39|\n",
      "+------------+-------------+-----+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hypertension_heart_disease_analysis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59aa698b-a158-4b8f-a9d5-9e99fd50ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoking status analysis\n",
    "smoking_analysis = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    smoking_status,\n",
    "    COUNT(*) as total,\n",
    "    SUM(CAST(stroke AS INT)) as stroke_cases,\n",
    "    ROUND(SUM(CAST(stroke AS INT)) * 100.0 / COUNT(*), 2) as stroke_rate_percent\n",
    "FROM stroke_data\n",
    "GROUP BY smoking_status\n",
    "ORDER BY stroke_rate_percent DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9add5338-878b-4de8-be5a-d664866362c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+------------+-------------------+\n",
      "| smoking_status|total|stroke_cases|stroke_rate_percent|\n",
      "+---------------+-----+------------+-------------------+\n",
      "|formerly smoked|  884|          69|               7.81|\n",
      "|         smokes|  789|          42|               5.32|\n",
      "|   never smoked| 1887|          90|               4.77|\n",
      "|        Unknown| 1540|          47|               3.05|\n",
      "+---------------+-----+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smoking_analysis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "abc1885a-1d09-4668-b1ef-fa0b8c0a7f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work type and stroke risk\n",
    "work_type_analysis = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    work_type,\n",
    "    COUNT(*) as total,\n",
    "    SUM(CAST(stroke AS INT)) as stroke_cases,\n",
    "    ROUND(SUM(CAST(stroke AS INT)) * 100.0 / COUNT(*), 2) as stroke_rate_percent\n",
    "FROM stroke_data\n",
    "GROUP BY work_type\n",
    "ORDER BY stroke_rate_percent DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f440dfbe-e4c6-4427-90c7-08ecb0c3e5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+------------+-------------------+\n",
      "|    work_type|total|stroke_cases|stroke_rate_percent|\n",
      "+-------------+-----+------------+-------------------+\n",
      "|Self-employed|  816|          65|               7.97|\n",
      "|      Private| 2920|         148|               5.07|\n",
      "|     Govt_job|  656|          33|               5.03|\n",
      "|     children|  686|           2|               0.29|\n",
      "| Never_worked|   22|           0|               0.00|\n",
      "+-------------+-----+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "work_type_analysis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ddb461be-17c2-448c-9c88-fc73dc3c44a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glucose level analysis by stroke status\n",
    "glucose_analysis = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    stroke,\n",
    "    ROUND(AVG(CAST(avg_glucose_level AS DOUBLE)), 2) as avg_glucose,\n",
    "    ROUND(MIN(CAST(avg_glucose_level AS DOUBLE)), 2) as min_glucose,\n",
    "    ROUND(MAX(CAST(avg_glucose_level AS DOUBLE)), 2) as max_glucose,\n",
    "    ROUND(STDDEV(CAST(avg_glucose_level AS DOUBLE)), 2) as std_glucose\n",
    "FROM stroke_data\n",
    "GROUP BY stroke\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27c61db7-867c-48fd-85f8-433481df6356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-----------+-----------+-----------+\n",
      "|stroke|avg_glucose|min_glucose|max_glucose|std_glucose|\n",
      "+------+-----------+-----------+-----------+-----------+\n",
      "|     0|     104.84|      55.12|     267.76|       43.9|\n",
      "|     1|     132.16|      56.11|     271.74|      61.74|\n",
      "+------+-----------+-----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "glucose_analysis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5344a424-dd75-4f37-88b7-748db79c1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI analysis by stroke status\n",
    "bmi_analysis = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    stroke,\n",
    "    ROUND(AVG(CASE WHEN bmi != 'N/A' THEN CAST(bmi AS DOUBLE) ELSE NULL END), 2) as avg_bmi,\n",
    "    ROUND(MIN(CASE WHEN bmi != 'N/A' THEN CAST(bmi AS DOUBLE) ELSE NULL END), 2) as min_bmi,\n",
    "    ROUND(MAX(CASE WHEN bmi != 'N/A' THEN CAST(bmi AS DOUBLE) ELSE NULL END), 2) as max_bmi\n",
    "FROM stroke_data\n",
    "GROUP BY stroke\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5fd86861-4266-43d2-9143-13cf7b885af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+\n",
      "|stroke|avg_bmi|min_bmi|max_bmi|\n",
      "+------+-------+-------+-------+\n",
      "|     0|  28.82|   10.3|   97.6|\n",
      "|     1|  30.44|   16.9|   56.6|\n",
      "+------+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bmi_analysis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93df4198-cacd-4d99-bd69-41a46aa42f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residence type comparison\n",
    "residence_analysis = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    Residence_type,\n",
    "    COUNT(*) as total,\n",
    "    SUM(CAST(stroke AS INT)) as stroke_cases,\n",
    "    ROUND(SUM(CAST(stroke AS INT)) * 100.0 / COUNT(*), 2) as stroke_rate_percent,\n",
    "    ROUND(AVG(CAST(age AS DOUBLE)), 2) as avg_age\n",
    "FROM stroke_data\n",
    "GROUP BY Residence_type\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ebe76ec-0bfe-452f-ad55-95ba82f8d39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+------------+-------------------+-------+\n",
      "|Residence_type|total|stroke_cases|stroke_rate_percent|avg_age|\n",
      "+--------------+-----+------------+-------------------+-------+\n",
      "|         Urban| 2591|         134|               5.17|  43.52|\n",
      "|         Rural| 2509|         114|               4.54|  42.89|\n",
      "+--------------+-----+------------+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "residence_analysis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "396ea84d-cf16-486d-9216-0ca359dc79f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-factor risk analysis\n",
    "multi_factor_risk = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    hypertension,\n",
    "    heart_disease,\n",
    "    smoking_status,\n",
    "    COUNT(*) as total,\n",
    "    SUM(CAST(stroke AS INT)) as stroke_cases,\n",
    "    ROUND(SUM(CAST(stroke AS INT)) * 100.0 / COUNT(*), 2) as stroke_rate_percent\n",
    "FROM stroke_data\n",
    "GROUP BY hypertension, heart_disease, smoking_status\n",
    "HAVING COUNT(*) > 10  -- Only show groups with sufficient data\n",
    "ORDER BY stroke_rate_percent DESC\n",
    "LIMIT 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b4213d66-3a70-4e7d-9a94-eefd1fe8ca3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+---------------+-----+------------+-------------------+\n",
      "|hypertension|heart_disease| smoking_status|total|stroke_cases|stroke_rate_percent|\n",
      "+------------+-------------+---------------+-----+------------+-------------------+\n",
      "|           1|            1|         smokes|   15|           5|              33.33|\n",
      "|           0|            1|         smokes|   46|          10|              21.74|\n",
      "|           1|            1|formerly smoked|   21|           4|              19.05|\n",
      "|           0|            1|        Unknown|   43|           8|              18.60|\n",
      "|           1|            1|   never smoked|   23|           4|              17.39|\n",
      "|           1|            0|formerly smoked|   99|          15|              15.15|\n",
      "|           1|            0|   never smoked|  207|          28|              13.53|\n",
      "|           0|            1|formerly smoked|   56|           7|              12.50|\n",
      "|           0|            1|   never smoked|   67|           8|              11.94|\n",
      "|           1|            0|        Unknown|   47|           4|               8.51|\n",
      "+------------+-------------+---------------+-----+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_factor_risk.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c0055cc-b2c6-4a3b-bd0b-6652a91e5a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality check for BMI\n",
    "data_quality_metrics = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) as total_records,\n",
    "    SUM(CASE WHEN bmi = 'N/A' THEN 1 ELSE 0 END) as missing_bmi,\n",
    "    ROUND(SUM(CASE WHEN bmi = 'N/A' THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) as missing_bmi_percent\n",
    "FROM stroke_data\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8d98a86-5f17-42c8-9095-c37322926298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-------------------+\n",
      "|total_records|missing_bmi|missing_bmi_percent|\n",
      "+-------------+-----------+-------------------+\n",
      "|         5100|        200|               3.92|\n",
      "+-------------+-----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_quality_metrics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "60ed89c1-ee17-4d73-9038-642cf5bf40bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age vs Glucose level correlation by stroke\n",
    "correlation_analysis = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    stroke,\n",
    "    ROUND(CORR(CAST(age AS DOUBLE), CAST(avg_glucose_level AS DOUBLE)), 3) as age_glucose_correlation\n",
    "FROM stroke_data\n",
    "GROUP BY stroke\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d58f3071-3e7a-43c6-a7ca-6f42b3410e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------+\n",
      "|stroke|age_glucose_correlation|\n",
      "+------+-----------------------+\n",
      "|     0|                  0.223|\n",
      "|     1|                   0.11|\n",
      "+------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correlation_analysis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d5b6a02c-4675-48e0-8dca-f2b16db69f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High-risk profile identification\n",
    "high_risk_profiles = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) as high_risk_count,\n",
    "    ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM stroke_data), 2) as percentage\n",
    "FROM stroke_data\n",
    "WHERE \n",
    "    CAST(age AS INT) > 60 \n",
    "    AND CAST(hypertension AS INT) = 1 \n",
    "    AND CAST(avg_glucose_level AS DOUBLE) > 200\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee370dc9-c13a-4da0-af74-449ad58c0a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+\n",
      "|high_risk_count|percentage|\n",
      "+---------------+----------+\n",
      "|             66|      1.29|\n",
      "+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "high_risk_profiles.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "25e02e9a-0953-4d15-83e6-4221b142124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numerical columns\n",
    "numerical_summary = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    'age' as column_name,\n",
    "    ROUND(MIN(CAST(age AS DOUBLE)), 2) as min_value,\n",
    "    ROUND(MAX(CAST(age AS DOUBLE)), 2) as max_value,\n",
    "    ROUND(AVG(CAST(age AS DOUBLE)), 2) as avg_value,\n",
    "    ROUND(STDDEV(CAST(age AS DOUBLE)), 2) as std_value\n",
    "FROM stroke_data\n",
    "UNION ALL\n",
    "SELECT \n",
    "    'avg_glucose_level' as column_name,\n",
    "    ROUND(MIN(CAST(avg_glucose_level AS DOUBLE)), 2) as min_value,\n",
    "    ROUND(MAX(CAST(avg_glucose_level AS DOUBLE)), 2) as max_value,\n",
    "    ROUND(AVG(CAST(avg_glucose_level AS DOUBLE)), 2) as avg_value,\n",
    "    ROUND(STDDEV(CAST(avg_glucose_level AS DOUBLE)), 2) as std_value\n",
    "FROM stroke_data\n",
    "UNION ALL\n",
    "SELECT \n",
    "    'bmi' as column_name,\n",
    "    ROUND(MIN(CASE WHEN bmi != 'N/A' THEN CAST(bmi AS DOUBLE) ELSE NULL END), 2) as min_value,\n",
    "    ROUND(MAX(CASE WHEN bmi != 'N/A' THEN CAST(bmi AS DOUBLE) ELSE NULL END), 2) as max_value,\n",
    "    ROUND(AVG(CASE WHEN bmi != 'N/A' THEN CAST(bmi AS DOUBLE) ELSE NULL END), 2) as avg_value,\n",
    "    ROUND(STDDEV(CASE WHEN bmi != 'N/A' THEN CAST(bmi AS DOUBLE) ELSE NULL END), 2) as std_value\n",
    "FROM stroke_data\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b4a52a49-ae07-4b52-bcb7-032c51f0c573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+---------+---------+---------+\n",
      "|      column_name|min_value|max_value|avg_value|std_value|\n",
      "+-----------------+---------+---------+---------+---------+\n",
      "|              age|     0.08|     82.0|    43.21|    22.61|\n",
      "|avg_glucose_level|    55.12|   271.74|   106.16|    45.31|\n",
      "|              bmi|     10.3|     97.6|    28.89|     7.85|\n",
      "+-----------------+---------+---------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numerical_summary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "64a49779-8bdd-4972-8d85-6e3b7d0120e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window functions for patient ranking\n",
    "patient_risk_scores = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    id,\n",
    "    age,\n",
    "    avg_glucose_level,\n",
    "    bmi,\n",
    "    hypertension,\n",
    "    heart_disease,\n",
    "    stroke,\n",
    "    ROUND(CAST(age AS DOUBLE) * 0.3 + \n",
    "          CAST(avg_glucose_level AS DOUBLE) * 0.01 + \n",
    "          CAST(hypertension AS INT) * 20 + \n",
    "          CAST(heart_disease AS INT) * 25, 2) as risk_score,\n",
    "    RANK() OVER (ORDER BY CAST(age AS DOUBLE) * 0.3 + \n",
    "                 CAST(avg_glucose_level AS DOUBLE) * 0.01 + \n",
    "                 CAST(hypertension AS INT) * 20 + \n",
    "                 CAST(heart_disease AS INT) * 25 DESC) as risk_rank\n",
    "FROM stroke_data\n",
    "WHERE bmi != 'N/A'\n",
    "ORDER BY risk_score DESC\n",
    "LIMIT 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2eb674c9-e143-4245-a498-d93717233dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------------+----+------------+-------------+------+----------+---------+\n",
      "|   id|age|avg_glucose_level| bmi|hypertension|heart_disease|stroke|risk_score|risk_rank|\n",
      "+-----+---+-----------------+----+------------+-------------+------+----------+---------+\n",
      "|20463| 81|           250.89|28.1|           1|            1|     1|     71.81|        1|\n",
      "|67895| 82|           215.94|27.9|           1|            1|     1|     71.76|        2|\n",
      "|65955| 81|           220.64|  30|           1|            1|     0|     71.51|        3|\n",
      "|63836| 81|           217.94|24.1|           1|            1|     0|     71.48|        4|\n",
      "|68627| 80|           175.29|31.5|           1|            1|     1|     70.75|        5|\n",
      "|62791| 79|           205.23|  22|           1|            1|     0|     70.75|        6|\n",
      "|28333| 79|           200.28|  30|           1|            1|     0|      70.7|        7|\n",
      "|54353| 78|           227.16|41.7|           1|            1|     0|     70.67|        8|\n",
      "|19271| 82|           101.56|31.5|           1|            1|     0|     70.62|        9|\n",
      "|70497| 81|           126.34|27.4|           1|            1|     0|     70.56|       10|\n",
      "+-----+---+-----------------+----+------------+-------------+------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patient_risk_scores.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de9faa3f-9435-4811-93e9-fb50a6d8cfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table - Stroke rate by age group and gender\n",
    "age_gender_pivot = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    gender,\n",
    "    ROUND(\n",
    "        SUM(CASE WHEN CAST(age AS INT) < 50 AND stroke = '1' THEN 1 ELSE 0 END) * 100.0 / \n",
    "        NULLIF(SUM(CASE WHEN CAST(age AS INT) < 50 THEN 1 ELSE 0 END), 0), \n",
    "        2\n",
    "    ) as under_50_stroke_rate,\n",
    "    ROUND(\n",
    "        SUM(CASE WHEN CAST(age AS INT) >= 50 AND stroke = '1' THEN 1 ELSE 0 END) * 100.0 / \n",
    "        NULLIF(SUM(CASE WHEN CAST(age AS INT) >= 50 THEN 1 ELSE 0 END), 0), \n",
    "        2\n",
    "    ) as over_50_stroke_rate\n",
    "FROM stroke_data\n",
    "GROUP BY gender\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ed4cc13f-8b3b-4b35-b196-5dd181efc7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-------------------+\n",
      "|gender|under_50_stroke_rate|over_50_stroke_rate|\n",
      "+------+--------------------+-------------------+\n",
      "|Female|                0.82|              10.00|\n",
      "|  Male|                0.51|              10.80|\n",
      "| Other|                0.00|               NULL|\n",
      "+------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "age_gender_pivot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c07148ec-a06d-4d71-8fe3-2bea9167e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL connection configuration\n",
    "postgres_host = \"44.202.107.137\"\n",
    "postgres_port = \"5432\"\n",
    "postgres_db = \"stroke_data_exploration\"\n",
    "postgres_user = \"analytics_user\"\n",
    "postgres_password = \"analytics_pass\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3e01360-f5eb-4af0-9493-7bb78a660279",
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_url = f\"jdbc:postgresql://{postgres_host}:{postgres_port}/{postgres_db}\"\n",
    "postgres_properties = {\n",
    "    \"user\": postgres_user,\n",
    "    \"password\": postgres_password,\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e76d4dd-e56f-4d2c-ac32-558d073998a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_spark_df_to_postgresql(spark_df, table_name, mode=\"replace\"):\n",
    "    \"\"\"\n",
    "    Write Spark DataFrame to PostgreSQL using psycopg2 and sqlalchemy\n",
    "    Modes: 'replace', 'append'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert Spark DataFrame to Pandas\n",
    "        pandas_df = spark_df.toPandas()\n",
    "        \n",
    "        # Create SQLAlchemy engine\n",
    "        from sqlalchemy import create_engine\n",
    "        engine = create_engine(f'postgresql://{postgres_user}:{postgres_password}@{postgres_host}:{postgres_port}/{postgres_db}')\n",
    "        \n",
    "        # Write Pandas DataFrame to PostgreSQL\n",
    "        pandas_df.to_sql(table_name, engine, if_exists=mode, index=False)\n",
    "        \n",
    "        print(f\"Successfully wrote {pandas_df.shape[0]} rows to {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to {table_name}: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3c9b8b3-cfbd-423c-ac18-1a6ea08e4e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote 5100 rows to stroke_raw_data\n"
     ]
    }
   ],
   "source": [
    "write_spark_df_to_postgresql(df, \"stroke_raw_data\", mode=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f709e48-41c5-4c5a-8923-3cc89d88cc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote 1 rows to dataset_overview\n"
     ]
    }
   ],
   "source": [
    "write_spark_df_to_postgresql(dataset_overview, \"dataset_overview\", mode=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6fba5b0c-b871-4f44-8cca-907becef2c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote 2 rows to stroke_distribution\n"
     ]
    }
   ],
   "source": [
    "write_spark_df_to_postgresql(stroke_distribution, \"stroke_distribution\", mode=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b1dfc219-441f-4860-9eaf-066f616a86b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote 3 rows to gender_analysis\n"
     ]
    }
   ],
   "source": [
    "write_spark_df_to_postgresql(gender_analysis, \"gender_analysis\", mode=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "22042a4c-48e7-448a-bcd2-fae3242eee17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote 4 rows to age_group_analysis\n"
     ]
    }
   ],
   "source": [
    "write_spark_df_to_postgresql(age_group_analysis, \"age_group_analysis\", mode=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "92d9dd4a-6fea-4ce0-a011-c2a176f1700f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote 4 rows to hypertension_heart_disease_analysis\n"
     ]
    }
   ],
   "source": [
    "write_spark_df_to_postgresql(hypertension_heart_disease_analysis, \"hypertension_heart_disease_analysis\", mode=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cd68d2f2-77bf-42ed-97a7-39656bc90206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote 4 rows to smoking_analysis\n"
     ]
    }
   ],
   "source": [
    "write_spark_df_to_postgresql(smoking_analysis, \"smoking_analysis\", mode=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7f73f9da-5c96-4891-9548-f795f51fe784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote 5 rows to work_type_analysis\n"
     ]
    }
   ],
   "source": [
    "write_spark_df_to_postgresql(work_type_analysis, \"work_type_analysis\", mode=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e1316d6a-c858-46b8-9bff-4c8f9d199672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote 2 rows to glucose_analysis\n"
     ]
    }
   ],
   "source": [
    "write_spark_df_to_postgresql(glucose_analysis, \"glucose_analysis\", mode=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "71ad6df9-0ac4-4f70-bd88-f8b2ed6c2c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote 2 rows to bmi_analysis\n"
     ]
    }
   ],
   "source": [
    "write_spark_df_to_postgresql(bmi_analysis, \"bmi_analysis\", mode=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7e22dc08-7ab2-41a6-b08e-17bb89655d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote 2 rows to residence_analysis\n"
     ]
    }
   ],
   "source": [
    "write_spark_df_to_postgresql(residence_analysis, \"residence_analysis\", mode=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fd2d03a3-7999-4348-a1a6-d1275fc9f800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote 10 rows to multi_factor_risk\n"
     ]
    }
   ],
   "source": [
    "write_spark_df_to_postgresql(multi_factor_risk, \"multi_factor_risk\", mode=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0c9021d8-8ef5-41f5-83f9-d3133e1bef5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote 1 rows to data_quality_metrics\n"
     ]
    }
   ],
   "source": [
    "write_spark_df_to_postgresql(data_quality_metrics, \"data_quality_metrics\", mode=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3085e273-9718-4a72-ad01-c950c29c4e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote 2 rows to correlation_analysis\n"
     ]
    }
   ],
   "source": [
    "write_spark_df_to_postgresql(correlation_analysis, \"correlation_analysis\", mode=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "637afe1b-ab7b-44da-81b5-248d640347dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote 1 rows to high_risk_profiles\n"
     ]
    }
   ],
   "source": [
    "write_spark_df_to_postgresql(high_risk_profiles, \"high_risk_profiles\", mode=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "71c2b85e-7d43-4b2d-b088-1d3df23e42ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote 3 rows to numerical_summary\n"
     ]
    }
   ],
   "source": [
    "write_spark_df_to_postgresql(numerical_summary, \"numerical_summary\", mode=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac992ea-1857-4456-9e4f-bd7fc26e2fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_spark_df_to_postgresql(patient_risk_scores, \"patient_risk_scores\", mode=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad153a7-1f53-4a9c-9568-39228600ec5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
